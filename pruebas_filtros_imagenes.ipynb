{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pruebas_filtros_imagenes",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNgbi2v3JmQHmmZozw+6xgW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marloquemegusta/filtros_para_imagenes/blob/master/pruebas_filtros_imagenes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9yizs9JWL-t"
      },
      "source": [
        "!git clone https://github.com/marloquemegusta/filtros_para_imagenes.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdB0qNWHQHxP"
      },
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageCms\n",
        "from skimage import feature\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from skimage.util import random_noise\n",
        "import glob\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow\n",
        "import matplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-3rO_UxXH0E"
      },
      "source": [
        "image_paths=glob.glob(\"/content/filtros_para_imagenes/imagenes/*\")\r\n",
        "images=[]\r\n",
        "widths=[]\r\n",
        "heights=[]\r\n",
        "for image_path in image_paths:\r\n",
        "  image=cv2.imread(image_path)\r\n",
        "  image=imutils.resize(image,1000)\r\n",
        "  images.append(image)\r\n",
        "max_height=max([image.shape[0] for image in images])\r\n",
        "for i,image in enumerate(images):\r\n",
        "  pad_amount=int((max_height-image.shape[0])/2)\r\n",
        "  images[i]=np.pad(image,((pad_amount,pad_amount),(0,0),(0,0)))\r\n",
        "  images[i]=cv2.resize(images[i],(1000,max_height))\r\n",
        "  \r\n",
        "images=np.array(images)\r\n",
        "W=images.shape[2]\r\n",
        "H=images.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ldyHU2qKUI"
      },
      "source": [
        "stack=np.zeros((max_height,1,3))\r\n",
        "for image in  images:\r\n",
        "  stack=np.hstack((stack,image))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQSJJrNdY_dR"
      },
      "source": [
        "# Expansión del rango dinámico"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Saw71S28ZEdj"
      },
      "source": [
        "En esta sección exploraremos varias maneras de expandir el rango dinámico de las imágenes para obtener un resultado más llamativo. Algo similar a lo que hace el algoritmo HDR. \r\n",
        "\r\n",
        "Las funciones descritas a continuación transforman la imagen de RGB a otro espacio de color para que la ecualización de histograma tenga sentido. Si aplicásemos la ecualización de histograma a alguno o a los tres canales en RGB obtendríamos una distorsión en los colores, no expansión en el rango dinámico. A continuación se enseña un ejemplo de qué pasaría al ecualizar los canales de color en RGB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBhtgnSXkAz6"
      },
      "source": [
        "stack=np.zeros((max_height*2,1,3))\r\n",
        "for i,image in enumerate(images):\r\n",
        "  image_eq_hist=image.copy()\r\n",
        "  for channel in range(3):\r\n",
        "    image_eq_hist[:,:,channel]=cv2.equalizeHist(image[:,:,channel])\r\n",
        "  stack=np.hstack((stack,np.vstack((image,image_eq_hist))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTeMw3HtY7hw"
      },
      "source": [
        "# en esta función convertimos la imagen a HSV y, en este formato, ecualizamos el\r\n",
        "# canal V (value). Este canal es el que representa la luminosidad, siendo 0 \r\n",
        "# un pixel totalmente negro y 255 un pixel totalmente blanco\r\n",
        "def valueHistEq(img):\r\n",
        "  img=img.copy() \r\n",
        "  HSV=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\r\n",
        "  HSV[:, :, 2] = cv2.equalizeHist(HSV[:, :, 2])\r\n",
        "  BGR=cv2.cvtColor(HSV,cv2.COLOR_HSV2BGR,img)\r\n",
        "  return BGR\r\n",
        "# en este caso hacemos lo mismo que en el anterior, pero esta vez no ecualizamos\r\n",
        "# el histograma de la imagen entera, sino que lo hacemos por bloques aplicando \r\n",
        "# un umbral máximo que no se puede superar (clipLimit)\r\n",
        "def clipValueHistEq(img,clipLimit=2.0,girdSize=(8,8)):\r\n",
        "  img=img.copy()\r\n",
        "  HSV=cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\r\n",
        "  HSV[:, :, 2] = cv2.equalizeHist(HSV[:, :, 2])\r\n",
        "  BGR=cv2.cvtColor(HSV,cv2.COLOR_HSV2BGR,img)\r\n",
        "  return BGR\r\n",
        "\r\n",
        "# Convertimos la imagen al formato YCrCb y ecualizamos el canal Y, también\r\n",
        "# correspondiente al brillo o luminosidad\r\n",
        "def yHistEq(img):\r\n",
        "  img=img.copy()\r\n",
        "  ycrcb=cv2.cvtColor(img,cv2.COLOR_BGR2YCR_CB)\r\n",
        "  ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\r\n",
        "  BGR=cv2.cvtColor(ycrcb,cv2.COLOR_YCR_CB2BGR,img)\r\n",
        "  return BGR\r\n",
        "\r\n",
        "\r\n",
        "def clipYHistEq(img,clipLimit=2.0,girdSize=(8,8)):\r\n",
        "  img=img.copy()\r\n",
        "  ycrcb=cv2.cvtColor(img,cv2.COLOR_BGR2YCR_CB)\r\n",
        "  clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\r\n",
        "  ycrcb[:, :, 0] = clahe.apply(ycrcb[:, :, 0].astype(\"uint8\"))\r\n",
        "  BGR=cv2.cvtColor(ycrcb,cv2.COLOR_YCR_CB2BGR,img)\r\n",
        "  return BGR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As9pAADKmY2G"
      },
      "source": [
        "#ecualización del histograma del canal V\r\n",
        "stack=np.zeros((max_height*2,1,3))\r\n",
        "for image in images:\r\n",
        "  image_eq_hist=valueHistEq(image)\r\n",
        "  stack=np.hstack((stack,np.vstack((image,image_eq_hist))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EjEFSY8sv3O"
      },
      "source": [
        "#ecualización del histograma del canal Y\r\n",
        "stack=np.zeros((max_height*2,1,3))\r\n",
        "for image in images:\r\n",
        "  image_eq_hist=yHistEq(image)\r\n",
        "  stack=np.hstack((stack,np.vstack((image,image_eq_hist))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmTxDZAmtAKH"
      },
      "source": [
        "#ecualización del histograma del canal V por bloques\r\n",
        "stack=np.zeros((max_height*2,1,3))\r\n",
        "for image in images:\r\n",
        "  image_eq_hist=clipValueHistEq(image)\r\n",
        "  stack=np.hstack((stack,np.vstack((image,image_eq_hist))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2-zYqIUtN8K"
      },
      "source": [
        "#ecualización del histograma del canal Y por bloques\r\n",
        "stack=np.zeros((max_height*2,1,3))\r\n",
        "for image in images:\r\n",
        "  image_eq_hist=clipYHistEq(image)\r\n",
        "  stack=np.hstack((stack,np.vstack((image,image_eq_hist))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHheRb87oKXA"
      },
      "source": [
        "# Detección de bordes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfKibktSAJsE"
      },
      "source": [
        "def get_colorized_edges(img,sigma=2):\n",
        "  img_gray= cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)\n",
        "  edges=feature.canny(img_gray,sigma=sigma).astype(\"uint8\")\n",
        "  kernel=np.ones((3,3))\n",
        "  edges=cv2.dilate(edges,kernel,iterations=1)\n",
        "  edged_im1=cv2.bitwise_and(np.asarray(img),np.asarray(img),mask=edges)\n",
        "  return edged_im1.astype(\"uint8\")\n",
        "\n",
        "def draw_edges_over_image(img,sigma=2,color=(0,0,0),offset=0,thikness=0):\n",
        "  img_gray= cv2.cvtColor(np.array(img), cv2.COLOR_BGR2GRAY)\n",
        "  edges=feature.canny(img_gray,sigma=sigma).astype(\"uint8\")\n",
        "  kernel=np.ones((3,3))\n",
        "  edges=cv2.dilate(edges,kernel,iterations=thikness)\n",
        "  edges=np.roll(edges,offset,axis=1)\n",
        "  edges_rgb=cv2.bitwise_and(np.ones(np.array(img).shape)*127,\n",
        "                            np.ones(np.array(img).shape)*127,\n",
        "                            mask=edges).astype(\"uint8\")\n",
        "  edges_rgb=np.where(edges_rgb==(127,127,127),color,(127,127,127))\n",
        "  edged_im2=np.where(edges_rgb!=(127,127,127),edges_rgb,np.array(img))\n",
        "  return edged_im2.astype(\"uint8\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYFCF8uJfyOW"
      },
      "source": [
        "Aquí podemos escoger como parámetro sigma, que representa la std del filtro gausiano que se aplica a la imagen antes de computar\r\n",
        "los bordes. Cuanto mayor sigma, menos bordes saldrán "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjJUxSubJZz1"
      },
      "source": [
        "#obteniendo bordes coloreados\r\n",
        "stack=np.zeros((max_height*3,1,3))\r\n",
        "for image in images:\r\n",
        "  image_colorized_borders_1=get_colorized_edges(image)\r\n",
        "  image_colorized_borders_2=get_colorized_edges(image,3)\r\n",
        "  stack=np.hstack((stack,np.vstack((image,image_colorized_borders_1,image_colorized_borders_2))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPa-hPZBLqK-"
      },
      "source": [
        "En este caso tenemos el parámetro sigma, el color del cual queremos pintar los bordes, el desplazamiento, en número de píxeles a la derecha, que queremos hacer de los bordes y su grosor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5seEQfg8LVZ0"
      },
      "source": [
        "# obteniendo bordes de la imagen\r\n",
        "stack=np.zeros((max_height*3,1,3))\r\n",
        "for image in images:\r\n",
        "  image_borders_1=draw_edges_over_image(image,\r\n",
        "                                        color=(255,255,255),\r\n",
        "                                        offset=0,\r\n",
        "                                        thikness=1,\r\n",
        "                                        sigma=3)\r\n",
        "  image_borders_2=draw_edges_over_image(image,\r\n",
        "                                        color=(255,255,255),\r\n",
        "                                        offset=50,\r\n",
        "                                        thikness=1,\r\n",
        "                                        sigma=3)\r\n",
        "  stack=np.hstack((stack,np.vstack((image,image_borders_1,image_borders_2))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CncAT2tCI2im"
      },
      "source": [
        "# Reducción del espacio de color"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Jgl4n8I5Dt"
      },
      "source": [
        "def reduce_color_space(img,ncolors=10):\r\n",
        "  imlab = cv2.cvtColor(np.array(img), cv2.COLOR_BGR2LAB)\r\n",
        "  (h, w) = imlab.shape[:2]\r\n",
        "  imlab = imlab.reshape((imlab.shape[0] * imlab.shape[1], 3))\r\n",
        "  kmeans = MiniBatchKMeans(n_clusters =ncolors)\r\n",
        "  labels = kmeans.fit_predict(imlab)\r\n",
        "  quant = kmeans.cluster_centers_.astype(\"uint8\")[labels]\r\n",
        "  quant = quant.reshape((h, w, 3))\r\n",
        "  return cv2.cvtColor(quant, cv2.COLOR_LAB2BGR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jovVgztCPnFR"
      },
      "source": [
        "En este caso lo que hacemos es aplicar una agrupación de los colores usando Kmeans. El número de clusters determina el número de colores en la imagen final. Una vez el algoritmo de Kmeans agrupa los colores, coloreamos la imagen utilizando, para cada color, el color más cercano de entre los centroides del Kmeans.\r\n",
        "Es importante aclarar que, dado que Kmeans busca grupos con la mínima distancia entre sus integrantes, hemos de transformar la imagen a un espacio de color donde haya una métrica de distancia relevante. Para esto utilizamos el espacio de color [LAB](https://es.wikipedia.org/wiki/Espacio_de_color_Lab)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vewvtuPNz6g"
      },
      "source": [
        "# reduciendo el espacio de color\r\n",
        "stack=np.zeros((max_height*4,1,3))\r\n",
        "for image in images:\r\n",
        "  image_3_colors=reduce_color_space(image,3)\r\n",
        "  image_8_colors=reduce_color_space(image,8)\r\n",
        "  image_64_colors= reduce_color_space(image,64)\r\n",
        "  stack=np.hstack((stack,np.vstack((image,image_3_colors,image_8_colors,image_64_colors))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz5JnWpIPhVk"
      },
      "source": [
        "# otros filtros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViSdn2dvPgmk"
      },
      "source": [
        "def shift_rgb(img,offset=10):\r\n",
        "  img=img.copy()\r\n",
        "  for channel in range(img.shape[2]):\r\n",
        "    img[:,:,channel]=np.roll(img[:,:,channel],offset*channel,axis=1)\r\n",
        "  return img\r\n",
        "\r\n",
        "def pixel_art(img,width=64, n_colors=32, border_thikness=0, sigma=1, orig_size=True):\r\n",
        "  img=img.copy()\r\n",
        "  img=reduce_color_space(img,n_colors)\r\n",
        "  img_mini=imutils.resize(img,width=width)\r\n",
        "  img_mini_edges=draw_edges_over_image(img_mini,thikness=border_thikness,sigma=sigma)\r\n",
        "  if orig_size:\r\n",
        "    img_orig_size_edges= cv2.resize(img_mini_edges,(img.shape[1],img.shape[0]),\r\n",
        "                                  interpolation = cv2.INTER_NEAREST)\r\n",
        "    return img_orig_size_edges\r\n",
        "  return img_mini_edges"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCMDyVw8dBH1"
      },
      "source": [
        "En esta sección compondremos varios efectos más, ya sea efectos que no encajan en las categorías anteriores o algunos que se forman por la adición de varios de los anteriores.\r\n",
        "\r\n",
        "En el primero trataremos de crear imágenes con estilo \"pixel art\", es decir, baja resolución, espacio de color reducido y bordes muy destacados. Los parámetros que podemos modificar son el tamaño de la imagen en píxeles (de ancho), el número de colores, el grosor de los bordes y la sigma del filtro gausiano."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihPhnVhodzyc"
      },
      "source": [
        "# reduciendo el espacio de color\r\n",
        "stack=np.zeros((max_height*3,1,3))\r\n",
        "for image in images:\r\n",
        "  pixel_art_64=pixel_art(image,\r\n",
        "                         sigma=1,\r\n",
        "                         width=64,\r\n",
        "                         n_colors=16)\r\n",
        "  pixel_art_128=pixel_art(image,\r\n",
        "                         sigma=2,\r\n",
        "                         width=128,\r\n",
        "                         n_colors=16)\r\n",
        "  stack=np.hstack((stack,np.vstack((image,pixel_art_64,pixel_art_128))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32V58qYLlvSX"
      },
      "source": [
        "En este siguiente filtro simplemente se desplazan los canales rojo, verde y azul de una imagen RGB para crear este efecto tan chulo. El único parámetro a ajustar es el desplazamiento que queremos entre los canales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJfzyIw3luwz"
      },
      "source": [
        "# desplazando los canales RGB\r\n",
        "stack=np.zeros((max_height*3,1,3))\r\n",
        "for image in images:\r\n",
        "  shifted_channels_10=shift_rgb(image,10)\r\n",
        "  shifted_channels_30=shift_rgb(image,30)\r\n",
        "  stack=np.hstack((stack,np.vstack((image,shifted_channels_10,shifted_channels_30))))\r\n",
        "cv2_imshow(stack)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}